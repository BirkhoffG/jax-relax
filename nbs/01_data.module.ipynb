{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module\n",
    "\n",
    "> `DataModule` for training parametric models, generating and benchmarking CF explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from relax.utils import show_doc\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "show_doc_parser = show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.utils import load_json, validate_configs, cat_normalize\n",
    "from relax.data.loader import Dataset, DataLoader, _supported_backends\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module Interfaces\n",
    "\n",
    "High-level interfaces for `DataModule`. Docs to be added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseDataModule(ABC):\n",
    "    \"\"\"DataModule Interface\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def data_name(self) -> str: \n",
    "        return\n",
    "        \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def data(self) -> Any:\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def train_dataset(self) -> Dataset:\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def val_dataset(self) -> Dataset:\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def test_dataset(self) -> Dataset:\n",
    "        return\n",
    "\n",
    "    def train_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def val_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_data(self) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, data) -> jnp.DeviceArray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def inverse_transform(self, x: jnp.DeviceArray) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def apply_constraints(\n",
    "        self, \n",
    "        x: jnp.DeviceArray,\n",
    "        cf: jnp.DeviceArray,\n",
    "        hard: bool\n",
    "    ) -> jnp.DeviceArray:\n",
    "        return cf\n",
    "    \n",
    "    def apply_regularization(\n",
    "        self, \n",
    "        x: jnp.DeviceArray,\n",
    "        cf: jnp.DeviceArray,\n",
    "        hard: bool\n",
    "    ):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabula Data Module\n",
    "\n",
    "`DataModule` for processing tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "def find_imutable_idx_list(\n",
    "    imutable_col_names: List[str],\n",
    "    discrete_col_names: List[str],\n",
    "    continuous_col_names: List[str],\n",
    "    cat_arrays: List[List[str]],\n",
    ") -> List[int]:\n",
    "    imutable_idx_list = []\n",
    "    for idx, col_name in enumerate(continuous_col_names):\n",
    "        if col_name in imutable_col_names:\n",
    "            imutable_idx_list.append(idx)\n",
    "\n",
    "    cat_idx = len(continuous_col_names)\n",
    "\n",
    "    for i, (col_name, cols) in enumerate(zip(discrete_col_names, cat_arrays)):\n",
    "        cat_end_idx = cat_idx + len(cols)\n",
    "        if col_name in imutable_col_names:\n",
    "            imutable_idx_list += list(range(cat_idx, cat_end_idx))\n",
    "        cat_idx = cat_end_idx\n",
    "    return imutable_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _check_cols(data: pd.DataFrame, configs: TabularDataModuleConfigs) -> pd.DataFrame:\n",
    "    data = data.astype({\n",
    "        col: float for col in configs.continous_cols\n",
    "    })\n",
    "    \n",
    "    cols = configs.continous_cols + configs.discret_cols\n",
    "    # check target columns\n",
    "    target_col = data.columns[-1]\n",
    "    assert not target_col in cols, \\\n",
    "        f\"continous_cols or discret_cols contains target_col={target_col}.\"\n",
    "    \n",
    "    # check imutable cols\n",
    "    for col in configs.imutable_cols:\n",
    "        assert col in cols, \\\n",
    "            f\"imutable_cols=[{col}] is not specified in `continous_cols` or `discret_cols`.\"\n",
    "    data = data[cols + [target_col]]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _process_data(\n",
    "    df: pd.DataFrame | None, configs: TabularDataModuleConfigs\n",
    ") -> pd.DataFrame:\n",
    "    if df is None:\n",
    "        df = pd.read_csv(configs.data_dir)\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        df = df\n",
    "    else:\n",
    "        raise ValueError(f\"{type(df).__name__} is not supported as an input type for `TabularDataModule`.\")\n",
    "\n",
    "    df = _check_cols(df, configs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _transform_df(\n",
    "    transformer: TransformerMixin,\n",
    "    data: pd.DataFrame,\n",
    "    cols: List[str] | None,\n",
    "):\n",
    "    return (\n",
    "        transformer.transform(data[cols])\n",
    "            if cols else np.array([[] for _ in range(len(data))])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "df = pd.read_csv('assets/data/s_adult.csv')\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = MinMaxScaler().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert x.shape == (len(df), len(cols))\n",
    "\n",
    "cols = []\n",
    "sca = MinMaxScaler()\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert x.shape == (len(df), len(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _inverse_transform_np(\n",
    "    transformer: TransformerMixin,\n",
    "    x: jnp.DeviceArray,\n",
    "    cols: List[str] | None\n",
    "):\n",
    "    assert len(cols) <= x.shape[-1], \\\n",
    "        f\"x.shape={x.shape} probably will not match len(cols)={len(cols)}\"\n",
    "    if cols:\n",
    "        data = transformer.inverse_transform(x)\n",
    "        return pd.DataFrame(data=data, columns=cols)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "df = pd.read_csv('assets/data/s_adult.csv')\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = MinMaxScaler().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert np.allclose(df[cols].values, data.values)\n",
    "\n",
    "cols = []\n",
    "sca = MinMaxScaler()\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert data is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "df = pd.read_csv('assets/data/s_adult.csv')\n",
    "cols = ['workclass', 'education']\n",
    "sca = OneHotEncoder().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape[0] == len(df)\n",
    "assert df[cols].equals(data)\n",
    "\n",
    "cols = []\n",
    "sca = OneHotEncoder()\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert data is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _init_scalar_encoder(\n",
    "    data: pd.DataFrame,\n",
    "    configs: TabularDataModuleConfigs\n",
    "):  \n",
    "    # fit scalar\n",
    "    if configs.normalizer:\n",
    "        scalar = configs.normalizer\n",
    "    else:\n",
    "        scalar = MinMaxScaler()\n",
    "        if configs.continous_cols:\n",
    "            scalar.fit(data[configs.continous_cols])\n",
    "    \n",
    "    # fit encoder\n",
    "    if configs.encoder:\n",
    "        encoder = configs.encoder\n",
    "    else:\n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        if configs.discret_cols:\n",
    "            encoder.fit(data[configs.discret_cols])\n",
    "    return dict(scalar=scalar, encoder=encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "class TabularDataModuleConfigs(BaseParser):\n",
    "    \"\"\"Configurator of `TabularDataModule`.\"\"\"\n",
    "\n",
    "    data_dir: str = Field(description=\"The directory of dataset.\")\n",
    "    data_name: str = Field(description=\"The name of `TabularDataModule`.\")\n",
    "    continous_cols: List[str] = Field(\n",
    "        [], description=\"Continuous features/columns in the data.\"\n",
    "    )\n",
    "    discret_cols: List[str] = Field(\n",
    "        [], description=\"Categorical features/columns in the data.\"\n",
    "    )\n",
    "    imutable_cols: List[str] = Field(\n",
    "        [], description=\"Immutable features/columns in the data.\"\n",
    "    )\n",
    "    normalizer: Optional[Any] = Field(\n",
    "        None, description=\"Fitted scalar for continuous features.\"\n",
    "    )\n",
    "    encoder: Optional[Any] = Field(\n",
    "        None, description=\"Fitted encoder for categorical features.\"\n",
    "    )\n",
    "    sample_frac: Optional[float] = Field(\n",
    "        None, description=\"Sample fraction of the data. Default to use the entire data.\", \n",
    "        ge=0., le=1.0\n",
    "    )\n",
    "    backend: str = Field(\n",
    "        \"jax\", description=f\"`Dataloader` backend. Currently supports: {_supported_backends()}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L176){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModuleConfigs\n",
       "\n",
       ">      TabularDataModuleConfigs (data_dir:str, data_name:str,\n",
       ">                                continous_cols:List[str]=[],\n",
       ">                                discret_cols:List[str]=[],\n",
       ">                                imutable_cols:List[str]=[],\n",
       ">                                normalizer:Union[Any,NoneType]=None,\n",
       ">                                encoder:Union[Any,NoneType]=None, sample_frac:U\n",
       ">                                nion[__main__.ConstrainedFloatValue,NoneType]=N\n",
       ">                                one, backend:str='jax')\n",
       "\n",
       "Configurator of `TabularDataModule`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data_dir | str |  | The directory of dataset. |\n",
       "| data_name | str |  | The name of `TabularDataModule`. |\n",
       "| continous_cols | List[str] | [] | Continuous features/columns in the data. |\n",
       "| discret_cols | List[str] | [] | Categorical features/columns in the data. |\n",
       "| imutable_cols | List[str] | [] | Immutable features/columns in the data. |\n",
       "| normalizer | Optional[Any] |  | Fitted scalar for continuous features. |\n",
       "| encoder | Optional[Any] |  | Fitted encoder for categorical features. |\n",
       "| sample_frac | Optional[float] |  | Sample fraction of the data. Default to use the entire data. |\n",
       "| backend | str | jax | `Dataloader` backend. Currently supports: ['jax', 'pytorch'] |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L176){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModuleConfigs\n",
       "\n",
       ">      TabularDataModuleConfigs (data_dir:str, data_name:str,\n",
       ">                                continous_cols:List[str]=[],\n",
       ">                                discret_cols:List[str]=[],\n",
       ">                                imutable_cols:List[str]=[],\n",
       ">                                normalizer:Union[Any,NoneType]=None,\n",
       ">                                encoder:Union[Any,NoneType]=None, sample_frac:U\n",
       ">                                nion[__main__.ConstrainedFloatValue,NoneType]=N\n",
       ">                                one, backend:str='jax')\n",
       "\n",
       "Configurator of `TabularDataModule`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data_dir | str |  | The directory of dataset. |\n",
       "| data_name | str |  | The name of `TabularDataModule`. |\n",
       "| continous_cols | List[str] | [] | Continuous features/columns in the data. |\n",
       "| discret_cols | List[str] | [] | Categorical features/columns in the data. |\n",
       "| imutable_cols | List[str] | [] | Immutable features/columns in the data. |\n",
       "| normalizer | Optional[Any] |  | Fitted scalar for continuous features. |\n",
       "| encoder | Optional[Any] |  | Fitted encoder for categorical features. |\n",
       "| sample_frac | Optional[float] |  | Sample fraction of the data. Default to use the entire data. |\n",
       "| backend | str | jax | `Dataloader` backend. Currently supports: ['jax', 'pytorch'] |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc_parser(TabularDataModuleConfigs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example configurator of the **adult** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = TabularDataModuleConfigs(\n",
    "    data_dir=\"assets/data/s_adult.csv\",\n",
    "    data_name=\"adult\",\n",
    "    continous_cols=[\"age\", \"hours_per_week\"],\n",
    "    discret_cols=[\"workclass\", \"education\", \"marital_status\",\"occupation\"],\n",
    "    imutable_cols=[\"age\", \"workclass\", \"marital_status\"],\n",
    "    normalizer=None, \n",
    "    encoder=None, \n",
    "    sample_frac=0.1,\n",
    "    backend='jax'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TabularDataModule(BaseDataModule):\n",
    "    \"\"\"DataModule for tabular data\"\"\"\n",
    "    cont_scalar = None # scalar for normalizing continuous features\n",
    "    cat_encoder = None # encoder for encoding categorical features\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_config: dict | TabularDataModuleConfigs, # Configurator of `TabularDataModule`\n",
    "        data: pd.DataFrame = None # Data in `pd.DataFrame`. If `data` is `None`, the DataModule will load data from `data_dir`.\n",
    "    ):\n",
    "        self._configs: TabularDataModuleConfigs = validate_configs(\n",
    "            data_config, TabularDataModuleConfigs\n",
    "        )\n",
    "        self._data = _process_data(data, self._configs)\n",
    "        # init idx lists\n",
    "        self.cat_idx = len(self._configs.continous_cols)\n",
    "        self._imutable_idx_list = []\n",
    "        self.prepare_data()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        scalar_encoder_dict = _init_scalar_encoder(\n",
    "            data=self._data, configs=self._configs\n",
    "        )\n",
    "        self.cont_scalar = scalar_encoder_dict['scalar']\n",
    "        self.cat_encoder = scalar_encoder_dict['encoder']\n",
    "        X, y = self.transform(self.data)\n",
    "\n",
    "        self._imutable_idx_list = find_imutable_idx_list(\n",
    "            imutable_col_names=self._configs.imutable_cols,\n",
    "            discrete_col_names=self._configs.discret_cols,\n",
    "            continuous_col_names=self._configs.continous_cols,\n",
    "            cat_arrays=self.cat_encoder.categories_,\n",
    "        )\n",
    "        \n",
    "        # prepare train & test\n",
    "        train_test_tuple = train_test_split(X, y, shuffle=False)\n",
    "        train_X, test_X, train_y, test_y = map(\n",
    "             lambda x: x.astype(float), train_test_tuple\n",
    "         )\n",
    "        if self._configs.sample_frac:\n",
    "            train_size = int(len(train_X) * self._configs.sample_frac)\n",
    "            train_X, train_y = train_X[:train_size], train_y[:train_size]\n",
    "        \n",
    "        self._train_dataset = Dataset(train_X, train_y)\n",
    "        self._val_dataset = Dataset(test_X, test_y)\n",
    "        self._test_dataset = self.val_dataset\n",
    "\n",
    "    @property\n",
    "    def data_name(self) -> str: \n",
    "        return self._configs.data_name\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        \"\"\"Loaded data in `pd.DataFrame`.\"\"\"\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def train_dataset(self) -> Dataset:\n",
    "        return self._train_dataset\n",
    "    \n",
    "    @property\n",
    "    def val_dataset(self) -> Dataset:\n",
    "        return self._val_dataset\n",
    "\n",
    "    @property\n",
    "    def test_dataset(self) -> Dataset:\n",
    "        return self._test_dataset\n",
    "\n",
    "    def train_dataloader(self, batch_size):\n",
    "        return DataLoader(self.train_dataset, self._configs.backend, \n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self, batch_size):\n",
    "        return DataLoader(self.val_dataset, self._configs.backend,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self, batch_size):\n",
    "        return DataLoader(self.val_dataset, self._configs.backend,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def transform(\n",
    "        self, \n",
    "        data: pd.DataFrame, # Data to be transformed to `numpy.ndarray`\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]: # Return `(X, y)`\n",
    "        \"\"\"Transform data into numerical representations.\"\"\"\n",
    "        # TODO: validate `data`\n",
    "        X_cont = _transform_df(\n",
    "            self.cont_scalar, data, self._configs.continous_cols\n",
    "        )\n",
    "        X_cat = _transform_df(\n",
    "            self.cat_encoder, data, self._configs.discret_cols\n",
    "        )\n",
    "        X = np.concatenate((X_cont, X_cat), axis=1)\n",
    "        y = data.iloc[:, -1:].to_numpy()\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def inverse_transform(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # The transformed input to be scaled back\n",
    "        y: jnp.DeviceArray = None # The transformed label to be scaled back. If `None`, the target columns will not be scaled back.\n",
    "    ) -> pd.DataFrame: # Transformed `pd.DataFrame`. \n",
    "        \"\"\"Scaled back into `pd.DataFrame`.\"\"\"\n",
    "        X_cont_df = _inverse_transform_np(\n",
    "            self.cont_scalar, x[:, :self.cat_idx], self._configs.continous_cols\n",
    "        )\n",
    "        X_cat_df = _inverse_transform_np(\n",
    "            self.cat_encoder, x[:, self.cat_idx:], self._configs.discret_cols\n",
    "        )\n",
    "        if y is not None:\n",
    "            y_df = pd.DataFrame(data=y, columns=[self.data.columns[-1]])\n",
    "        else:\n",
    "            y_df = None\n",
    "        \n",
    "        return pd.concat(\n",
    "            [X_cont_df, X_cat_df, y_df], axis=1\n",
    "        )\n",
    "\n",
    "    def apply_constraints(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # input\n",
    "        cf: jnp.DeviceArray, # Unnormalized counterfactuals\n",
    "        hard: bool = False # Apply hard constraints or not\n",
    "    ) -> jnp.DeviceArray:\n",
    "        \"\"\"Apply categorical normalization and immutability constraints\"\"\"\n",
    "        cat_arrays = self.cat_encoder.categories_ \\\n",
    "            if self._configs.discret_cols else []\n",
    "        cf = cat_normalize(\n",
    "            cf, cat_arrays=cat_arrays, \n",
    "            cat_idx=len(self._configs.continous_cols),\n",
    "            hard=hard\n",
    "        )\n",
    "        # apply immutable constraints\n",
    "        if len(self._configs.imutable_cols) > 0:\n",
    "            cf = cf.at[:, self._imutable_idx_list].set(x[:, self._imutable_idx_list])\n",
    "        return cf\n",
    "\n",
    "    def apply_regularization(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # Input\n",
    "        cf: jnp.DeviceArray, # Unnormalized counterfactuals\n",
    "    ) -> float: # Return regularization loss\n",
    "        \"\"\"Apply categorical constraints by adding regularization terms\"\"\"\n",
    "        reg_loss = 0.\n",
    "        cat_arrays = self.cat_encoder.categories_\n",
    "        cat_idx = len(self._configs.continous_cols)\n",
    "\n",
    "        for col in cat_arrays:\n",
    "            cat_idx_end = cat_idx + len(col)\n",
    "            reg_loss += jnp.power(\n",
    "                (jnp.sum(cf[cat_idx:cat_idx_end]) - 1.0), 2\n",
    "            )\n",
    "        return reg_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load `TabularDataModule` from `TabularDataModuleConfigs`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TabularDataModule(configs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly pass a `pd.DataFrame` to `TabularDataModule`. \n",
    "In this case, `TabularDataModule` will use the passed `pd.DataFrame`, instead of loading data from `data_dir` in `TabularDataModuleConfigs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/data/s_adult.csv')[:1000]\n",
    "dm = TabularDataModule(configs, data=df)\n",
    "assert len(dm.data) == 1000 # dm contains `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L257){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.data\n",
       "\n",
       ">      TabularDataModule.data ()\n",
       "\n",
       "Loaded data in `pd.DataFrame`."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L257){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.data\n",
       "\n",
       ">      TabularDataModule.data ()\n",
       "\n",
       "Loaded data in `pd.DataFrame`."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabulaDataModule` loads either a csv file (specified in `data_dir` in `data_config`), \n",
    "or directly passes a DataFrame (specified as `data`). \n",
    "Either way, this data needs to satisfy following conditions:\n",
    "\n",
    "* It requires the **target column** (i.e., the labels) to be the **last** column of the DataFrame, \n",
    "and the rest columns are **features**. \n",
    "This **target column** needs to be binary-valued (i.e., it is either `0` or `1`).\n",
    "    * In the belowing example, **income** is the **target column**, and the rest columns are features.\n",
    "* It requires `continous_cols` and `discret_cols` in `data_config` to be subsets of `data.columns`.\n",
    "* It only use columns specified in `continous_cols` and `discret_cols`.\n",
    "    * It loads `continous_cols` first, then `discret_cols`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  income  \n",
       "0   Blue-Collar       1  \n",
       "1   Blue-Collar       0  \n",
       "2  White-Collar       1  \n",
       "3   Blue-Collar       0  \n",
       "4       Service       0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L289){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.transform\n",
       "\n",
       ">      TabularDataModule.transform (data:pandas.core.frame.DataFrame)\n",
       "\n",
       "Transform data into numerical representations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| data | pd.DataFrame | Data to be transformed to `numpy.ndarray` |\n",
       "| **Returns** | **Tuple[np.ndarray, np.ndarray]** | **Return `(X, y)`** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L289){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.transform\n",
       "\n",
       ">      TabularDataModule.transform (data:pandas.core.frame.DataFrame)\n",
       "\n",
       "Transform data into numerical representations.\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| data | pd.DataFrame | Data to be transformed to `numpy.ndarray` |\n",
       "| **Returns** | **Tuple[np.ndarray, np.ndarray]** | **Return `(X, y)`** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we transform *continuous features* via `MinMaxScaler`, \n",
    "and *discrete features* via `OneHotEncoding`. \n",
    "\n",
    "A tabular data point $x$ is encoded as \n",
    "$$x = [\\underbrace{x_{0}, x_{1}, ..., x_{m}}_{\\text{cont features}}, \n",
    "\\underbrace{x_{m+1}^{c=1},..., x_{m+p}^{c=1}}_{\\text{cat feature} (1)}, ..., \n",
    "\\underbrace{x_{k-q}^{c=i},..., x_{k}^{^{c=i}}}_{\\text{cat feature} (i)}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dm.data.head()\n",
    "X, y = dm.transform(df)\n",
    "\n",
    "assert isinstance(X, np.ndarray)\n",
    "assert isinstance(y, np.ndarray)\n",
    "assert y.shape == (len(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L306){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.inverse_transform\n",
       "\n",
       ">      TabularDataModule.inverse_transform\n",
       ">                                           (x:jaxlib.xla_extension.DeviceArrayB\n",
       ">                                           ase, y:jaxlib.xla_extension.DeviceAr\n",
       ">                                           rayBase=None)\n",
       "\n",
       "Scaled back into `pd.DataFrame`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| x | jnp.DeviceArray |  | The transformed input to be scaled back |\n",
       "| y | jnp.DeviceArray | None | The transformed label to be scaled back. If `None`, the target columns will not be scaled back. |\n",
       "| **Returns** | **pd.DataFrame** |  | **Transformed `pd.DataFrame`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L306){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.inverse_transform\n",
       "\n",
       ">      TabularDataModule.inverse_transform\n",
       ">                                           (x:jaxlib.xla_extension.DeviceArrayB\n",
       ">                                           ase, y:jaxlib.xla_extension.DeviceAr\n",
       ">                                           rayBase=None)\n",
       "\n",
       "Scaled back into `pd.DataFrame`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| x | jnp.DeviceArray |  | The transformed input to be scaled back |\n",
       "| y | jnp.DeviceArray | None | The transformed label to be scaled back. If `None`, the target columns will not be scaled back. |\n",
       "| **Returns** | **pd.DataFrame** |  | **Transformed `pd.DataFrame`.** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.inverse_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabularDataModule.inverse_transform` scales numerical representations back\n",
    "to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  income  \n",
       "0   Blue-Collar       1  \n",
       "1   Blue-Collar       0  \n",
       "2  White-Collar       1  \n",
       "3   Blue-Collar       0  \n",
       "4       Service       0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.inverse_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `y` is not passed, it will only scale back `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  \n",
       "0   Blue-Collar  \n",
       "1   Blue-Collar  \n",
       "2  White-Collar  \n",
       "3   Blue-Collar  \n",
       "4       Service  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.apply_constraints\n",
       "\n",
       ">      TabularDataModule.apply_constraints\n",
       ">                                           (x:jaxlib.xla_extension.DeviceArrayB\n",
       ">                                           ase, cf:jaxlib.xla_extension.DeviceA\n",
       ">                                           rrayBase, hard:bool=False)\n",
       "\n",
       "Apply categorical normalization and immutability constraints\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| x | jnp.DeviceArray |  | input |\n",
       "| cf | jnp.DeviceArray |  | Unnormalized counterfactuals |\n",
       "| hard | bool | False | Apply hard constraints or not |\n",
       "| **Returns** | **jnp.DeviceArray** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/data/module.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TabularDataModule.apply_constraints\n",
       "\n",
       ">      TabularDataModule.apply_constraints\n",
       ">                                           (x:jaxlib.xla_extension.DeviceArrayB\n",
       ">                                           ase, cf:jaxlib.xla_extension.DeviceA\n",
       ">                                           rrayBase, hard:bool=False)\n",
       "\n",
       "Apply categorical normalization and immutability constraints\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| x | jnp.DeviceArray |  | input |\n",
       "| cf | jnp.DeviceArray |  | Unnormalized counterfactuals |\n",
       "| hard | bool | False | Apply hard constraints or not |\n",
       "| **Returns** | **jnp.DeviceArray** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.apply_constraints)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabularDataModule.apply_constraints` does two things: \n",
    "\n",
    "1. It ensures that generated counterfactuals respect the one-hot encoding format (i.e., $\\sum_{p \\to q} x^{c=i}_{p} = 1$).\n",
    "2. It ensures the immutability constraints (i.e., immutable features defined in `imutable_cols` will not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dm.test_dataloader(batch_size=128)))\n",
    "# unnormalized counterfactuals\n",
    "cf = random.normal(\n",
    "    random.PRNGKey(0), x.shape\n",
    ")\n",
    "# normalized counterfactuals\n",
    "cf_normed = dm.apply_constraints(x, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### TabularDataModule.apply_regularization\n",
       "\n",
       ">      TabularDataModule.apply_regularization\n",
       ">                                              (x:jaxlib.xla_extension.DeviceArr\n",
       ">                                              ayBase, cf:jaxlib.xla_extension.D\n",
       ">                                              eviceArrayBase)\n",
       "\n",
       "Apply categorical constraints by adding regularization terms\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| x | jnp.DeviceArray | Input |\n",
       "| cf | jnp.DeviceArray | Unnormalized counterfactuals |\n",
       "| **Returns** | **float** | **Return regularization loss** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### TabularDataModule.apply_regularization\n",
       "\n",
       ">      TabularDataModule.apply_regularization\n",
       ">                                              (x:jaxlib.xla_extension.DeviceArr\n",
       ">                                              ayBase, cf:jaxlib.xla_extension.D\n",
       ">                                              eviceArrayBase)\n",
       "\n",
       "Apply categorical constraints by adding regularization terms\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| x | jnp.DeviceArray | Input |\n",
       "| cf | jnp.DeviceArray | Unnormalized counterfactuals |\n",
       "| **Returns** | **float** | **Return regularization loss** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.apply_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dm.test_dataloader(batch_size=128)))\n",
    "# unnormalized counterfactuals\n",
    "cf = random.normal(\n",
    "    random.PRNGKey(0), x.shape\n",
    ")\n",
    "# normalized counterfactuals\n",
    "cf_normed = dm.apply_constraints(x, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample(datamodule: BaseDataModule, frac: float = 1.0): \n",
    "    X, y = datamodule.train_dataset[:]\n",
    "    size = int(len(X) * frac)\n",
    "    return X[:size], y[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def check_datamodule(dm: TabularDataModule, data_configs: dict | TabularDataModuleConfigs):\n",
    "    batch_size = 256\n",
    "    data_configs = validate_configs(data_configs, TabularDataModuleConfigs)\n",
    "    cat_idx = len(data_configs.continous_cols)\n",
    "    n_cat_feat = len(data_configs.discret_cols)\n",
    "\n",
    "    feats, label = dm.train_dataset[:]\n",
    "    assert feats.shape[0] == len(label)\n",
    "    assert label.shape == (feats.shape[0], 1)\n",
    "\n",
    "    X, y = dm.val_dataset[:]\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    X, y = dm.test_dataset[:]\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    dl = dm.train_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    dl = dm.val_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    dl = dm.test_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    ############################################################\n",
    "    # test `transform` and `inverse_transform`\n",
    "    ############################################################\n",
    "    df = dm.inverse_transform(feats, label)\n",
    "    assert len(df) == len(feats)\n",
    "    assert len(df.columns) == cat_idx + n_cat_feat + 1\n",
    "\n",
    "    X_transformed, y = dm.transform(df)\n",
    "    assert np.allclose(feats, X_transformed)\n",
    "    assert np.allclose(y, label)\n",
    "    \n",
    "    ############################################################\n",
    "    # test `apply_constraints` ad `project`\n",
    "    ##########################################################\n",
    "    dl = dm.test_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    cf = random.normal(\n",
    "        random.PRNGKey(0), x.shape\n",
    "    )\n",
    "    cf = dm.apply_constraints(x, cf, hard=False)\n",
    "    assert jnp.allclose(jnp.sum(cf[:, cat_idx:]), len(cf) * n_cat_feat)\n",
    "\n",
    "    cf = dm.apply_constraints(x, cf, hard=True)\n",
    "    assert jnp.count_nonzero(cf == 1) == len(cf) * n_cat_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data_configs = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    'sample_frac': 0.1,\n",
    "    \"continous_cols\": [\"age\", \"hours_per_week\"],\n",
    "    \"discret_cols\": [\n",
    "        \"workclass\", \"education\", \"marital_status\",\n",
    "        \"occupation\", \"race\", \"gender\"\n",
    "    ],\n",
    "}\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)\n",
    "\n",
    "# immutable\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs[\"imutable_cols\"] = [\"race\",\"gender\"]\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)\n",
    "\n",
    "# no cont\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs['continous_cols'] = []\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)\n",
    "\n",
    "# no cat\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs['discret_cols'] = []\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "High-level util function for loading `data` and `data_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "DEFAULT_DATA_CONFIGS = {\n",
    "    'adult': {\n",
    "        'data' :'assets/data/s_adult.csv',\n",
    "        'conf' :'assets/configs/data_configs/adult.json',\n",
    "    },\n",
    "    'heloc': {\n",
    "        'data': 'assets/data/s_home.csv',\n",
    "        'conf': 'assets/configs/data_configs/home.json'\n",
    "    },\n",
    "    'oulad': {\n",
    "        'data': 'assets/data/s_student.csv',\n",
    "        'conf': 'assets/configs/data_configs/student.json'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _validate_dataname(data_name: str):\n",
    "    if data_name not in DEFAULT_DATA_CONFIGS.keys():\n",
    "        raise ValueError(f'`data_name` must be one of {DEFAULT_DATA_CONFIGS.keys()}, '\n",
    "            f'but got data_name={data_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(\n",
    "    data_name: str, # The name of data\n",
    "    return_config: bool = False, # Return `data_config `or not\n",
    "    data_configs: dict = None # Data configs to override default configuration\n",
    ") -> TabularDataModule | Tuple[TabularDataModule, TabularDataModuleConfigs]: \n",
    "    _validate_dataname(data_name)\n",
    "\n",
    "    # get data/config urls\n",
    "    _data_path = DEFAULT_DATA_CONFIGS[data_name]['data']\n",
    "    _conf_path = DEFAULT_DATA_CONFIGS[data_name]['conf']\n",
    "    \n",
    "    data_url = f\"https://github.com/BirkhoffG/cfnet/raw/master/{_data_path}\"\n",
    "    conf_url = f\"https://github.com/BirkhoffG/cfnet/raw/master/{_conf_path}\"\n",
    "\n",
    "    # create new dir\n",
    "    data_dir = Path(os.getcwd()) / \"cf_data\"\n",
    "    if not data_dir.exists():\n",
    "        os.makedirs(data_dir)\n",
    "    data_path = data_dir / f'{data_name}.csv'\n",
    "    conf_path = data_dir / f'{data_name}.json'\n",
    "\n",
    "    # download data/configs\n",
    "    if not data_path.is_file():\n",
    "        urlretrieve(data_url, data_path)    \n",
    "    if not conf_path.is_file():\n",
    "        urlretrieve(conf_url, conf_path)\n",
    "\n",
    "    # read config\n",
    "    config = load_json(conf_path)['data_configs']\n",
    "    config['data_dir'] = str(data_path)\n",
    "\n",
    "    if not (data_configs is None):\n",
    "        config.update(data_configs)\n",
    "\n",
    "    config = TabularDataModuleConfigs(**config)\n",
    "    data_module = TabularDataModule(config)\n",
    "\n",
    "    if return_config:\n",
    "        return data_module, config\n",
    "    else:\n",
    "        return data_module\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Cont Feats</th>\n",
       "      <th># Cat Feats</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heloc</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>10459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oulad</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>32593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       # Cont Feats  # Cat Feats   Size\n",
       "adult             2            6  32561\n",
       "heloc            21            2  10459\n",
       "oulad            23            8  32593"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "def display_data_attrbutes(names: list):\n",
    "    attrs = {\n",
    "        '# Cont Feats': { data_name: 0 for data_name in names}, \n",
    "        '# Cat Feats': { data_name: 0 for data_name in names},\n",
    "        'Size': { data_name: 0 for data_name in names}, \n",
    "    }\n",
    "    for data_name in names:\n",
    "        dm, config = load_data(data_name, return_config=True)\n",
    "        attrs['# Cont Feats'][data_name] = len(config.continous_cols)\n",
    "        attrs['# Cat Feats'][data_name] = len(config.discret_cols)\n",
    "        attrs['Size'][data_name] = len(dm.data)\n",
    "\n",
    "        # run tests\n",
    "        check_datamodule(dm, config)\n",
    "    return pd.DataFrame.from_dict(attrs)\n",
    "\n",
    "display_data_attrbutes(DEFAULT_DATA_CONFIGS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for data_name in DEFAULT_DATA_CONFIGS.keys():\n",
    "    dm, config = load_data(\n",
    "        data_name, return_config=True, data_configs=dict(sample_frac=0.1)\n",
    "    )\n",
    "    assert config.sample_frac == 0.1\n",
    "    check_datamodule(dm, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
