{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp methods.vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.methods.base import CFModule\n",
    "from relax.base import BaseConfig\n",
    "from relax.utils import auto_reshaping, grad_update, validate_configs, get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from relax.ml_model import MLModule\n",
    "from relax.data_module import load_data\n",
    "from relax.ml_model import load_ml_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "@ft.partial(jit, static_argnums=(2, 3, 6, 7, 8))\n",
    "def _vanilla_cf(\n",
    "    x: jnp.DeviceArray,  # `x` shape: (k,), where `k` is the number of features\n",
    "    y_target: Array, # `y_target` shape: (1,)\n",
    "    pred_fn: Callable[[Array], Array],  # y = pred_fn(x)\n",
    "    n_steps: int,\n",
    "    lr: float,  # learning rate for each `cf` optimization step\n",
    "    lambda_: float,  #  loss = validity_loss + lambda_params * cost\n",
    "    validity_fn: Callable,\n",
    "    cost_fn: Callable,\n",
    "    apply_constraints_fn: Callable, \n",
    "    rng_key: jnp.ndarray, # rng_key for initializing `cf`\n",
    ") -> jnp.DeviceArray:  # return `cf` shape: (k,)\n",
    "    @jit\n",
    "    def loss_fn_1(y_true: Array, y_pred: Array):\n",
    "        return validity_fn(y_true, y_pred).mean()\n",
    "\n",
    "    @jit\n",
    "    def loss_fn_2(x: Array, cf: Array):\n",
    "        return cost_fn(cf, x).mean()\n",
    "\n",
    "    @partial(jit, static_argnums=(2,))\n",
    "    def loss_fn(\n",
    "        cf: Array,  # `cf` shape: (k, 1)\n",
    "        x: Array,  # `x` shape: (k, 1)\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "    ):\n",
    "        cf_y_pred = pred_fn(cf)\n",
    "        return loss_fn_1(y_target, cf_y_pred) + lambda_ * loss_fn_2(x, cf)\n",
    "\n",
    "    @loop_tqdm(n_steps)\n",
    "    def gen_cf_step(\n",
    "        i, cf_opt_state: Tuple[Array, optax.OptState] #x: Array, cf: Array, opt_state: optax.OptState\n",
    "    ) -> Tuple[jnp.DeviceArray, optax.OptState]:\n",
    "        cf, opt_state = cf_opt_state\n",
    "        cf_grads = jax.grad(loss_fn)(cf, x, pred_fn)\n",
    "        cf, opt_state = grad_update(cf_grads, cf, opt_state, opt)\n",
    "        cf = apply_constraints_fn(x, cf, hard=False)\n",
    "        return cf, opt_state\n",
    "\n",
    "    cf = jnp.array(x, copy=True)\n",
    "    # Add noise to `cf` to avoid gradient=0; see https://github.com/BirkhoffG/jax-relax/issues/46\n",
    "    cf = jrand.uniform(rng_key, cf.shape, minval=-0.1, maxval=0.1) + cf\n",
    "    opt = optax.rmsprop(lr)\n",
    "    opt_state = opt.init(cf)\n",
    "    cf, opt_state = lax.fori_loop(0, n_steps, gen_cf_step, (cf, opt_state))\n",
    "\n",
    "    cf = apply_constraints_fn(x, cf, hard=True)\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VanillaCFConfig(BaseConfig):\n",
    "    n_steps: int = 100\n",
    "    lr: float = 0.1\n",
    "    lambda_: float = 0.1\n",
    "    validity_fn: str = 'KLDivergence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class VanillaCF(CFModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: dict | VanillaCFConfig = None,\n",
    "        name: str = None,\n",
    "    ):\n",
    "        if config is None:\n",
    "            config = VanillaCFConfig()\n",
    "        config = validate_configs(config, VanillaCFConfig)\n",
    "        name = \"VanillaCF\" if name is None else name\n",
    "        super().__init__(config, name=name)\n",
    "\n",
    "    def save(self, path: str):\n",
    "        self.config.save(Path(path) / 'config.json')\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_path(cls, path: str):\n",
    "        config = VanillaCFConfig.load_from_json(Path(path) / 'config.json')\n",
    "        return cls(config=config)\n",
    "\n",
    "    @auto_reshaping('x')\n",
    "    def generate_cf(\n",
    "        self,\n",
    "        x: Array,  # `x` shape: (k,), where `k` is the number of features\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "        y_target: Array = None,\n",
    "        rng_key: jrand.PRNGKey = None,\n",
    "        **kwargs,\n",
    "    ) -> jnp.DeviceArray:\n",
    "        # TODO: Currently assumes binary classification.\n",
    "        if y_target is None:\n",
    "            y_target = 1 - pred_fn(x)\n",
    "        else:\n",
    "            y_target = jnp.array(y_target, copy=True)\n",
    "        if rng_key is None:\n",
    "            rng_key = jrand.PRNGKey(get_config().global_seed)\n",
    "\n",
    "        return _vanilla_cf(\n",
    "            x=x,  # `x` shape: (k,), where `k` is the number of features\n",
    "            y_target=y_target,  # `y_target` shape: (1,)\n",
    "            pred_fn=pred_fn,  # y = pred_fn(x)\n",
    "            n_steps=self.config.n_steps,\n",
    "            lr=self.config.lr,  # learning rate for each `cf` optimization step\n",
    "            lambda_=self.config.lambda_,  #  loss = validity_loss + lambda_params * cost\n",
    "            validity_fn=keras.losses.get({'class_name': self.config.validity_fn, 'config': {'reduction': None}}),\n",
    "            cost_fn=keras.losses.get({'class_name': 'MeanSquaredError', 'config': {'reduction': None}}),\n",
    "            apply_constraints_fn=self.apply_constraints,\n",
    "            rng_key=rng_key,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data('dummy')\n",
    "model = load_ml_module('dummy')\n",
    "xs_train, ys_train = dm['train']\n",
    "xs_test, ys_test = dm['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6253566d36394a1b8e280d733e4f8dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602447b7e5b04674bf3b6ace98cdd9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity:  0.99600005\n"
     ]
    }
   ],
   "source": [
    "vcf = VanillaCF()\n",
    "cf = vcf.generate_cf(xs_test[0], model.pred_fn)\n",
    "assert cf.shape == xs_test[0].shape\n",
    "\n",
    "partial_gen = ft.partial(vcf.generate_cf, pred_fn=model.pred_fn)\n",
    "cfs = jax.vmap(partial_gen)(xs_test)\n",
    "\n",
    "print(\"Validity: \", keras.metrics.binary_accuracy(\n",
    "    (1 - model.pred_fn(xs_test)).round(),\n",
    "    model.pred_fn(cfs)\n",
    ").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beaf7a9388641888b9ad37f66816f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity:  0.98800004\n"
     ]
    }
   ],
   "source": [
    "def apply_constraint_fn(x, cf, hard=False):\n",
    "    return jax.lax.cond(\n",
    "        hard,\n",
    "        lambda: jnp.clip(cf, 0, 1),\n",
    "        lambda: cf,\n",
    "    )\n",
    "\n",
    "vcf.set_apply_constraints_fn(apply_constraint_fn)\n",
    "cfs = jax.vmap(partial_gen)(xs_test)\n",
    "\n",
    "print(\"Validity: \", keras.metrics.binary_accuracy(\n",
    "    (1 - model.pred_fn(xs_test)).round(),\n",
    "    model.pred_fn(cfs)\n",
    ").mean())\n",
    "assert (cfs >= 0).all() and (cfs <= 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d179274d962f4ab5a95022deb0743c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vcf.save('tmp/vanillacf/')\n",
    "vcf_1 = VanillaCF.load_from_path('tmp/vanillacf/')\n",
    "vcf_1.set_apply_constraints_fn(apply_constraint_fn)\n",
    "partial_gen_1 = ft.partial(vcf_1.generate_cf, pred_fn=model.pred_fn)\n",
    "cfs_1 = jax.vmap(partial_gen_1)(xs_test)\n",
    "\n",
    "assert jnp.allclose(cfs, cfs_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
