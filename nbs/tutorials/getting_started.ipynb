{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| all_slow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5562079",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "> A basic tutorial of key features in `ReLax`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "962171c1",
   "metadata": {},
   "source": [
    "This tutorial aims at introducing basics about `ReLax`, \n",
    "and how to use `ReLax` to generate counterfactual (or recourse)\n",
    "explanations for `jax`-based implementations of ML models.\n",
    "\n",
    "\n",
    "In particular, we will cover the following things in this tutorial:\n",
    "\n",
    "1. Loading datasets with `TabularDataModule`;\n",
    "2. Training machine learning classifiers;\n",
    "3. Generating counterfactual (or recourse) explanations;\n",
    "4. Benchmarking different recourse methods.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bb51830",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "We assume that you have already installed `ReLax`. \n",
    "If not, follow the steps in [this installation tutorial](install.ipynb), or\n",
    "just enter `pip install jax-relax`.\n",
    "\n",
    "We also want to import some libraries for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a77c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e973a075",
   "metadata": {},
   "source": [
    "## Load Dataset with `TabularDataModule`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "276359a8",
   "metadata": {},
   "source": [
    "`TabularDataModule` is a python class which modularizes tabular dataset loading. \n",
    "`TabularDataModule` loads a `.csv` file from the directory by specifying the following attributes:\n",
    "\n",
    "- `data_name` is the name of your dataset.\n",
    "- `data_dir` should contain the relative path of the directory \n",
    "where your dataset is located.\n",
    "- `continous_cols` specifies a list of feature names representing \n",
    "all the continuous/numeric features in our dataset.\n",
    "- `discret_cols` specifies a list of feature names representing all discrete features in our dataset. \n",
    "By default, all discrete features are converted via one-hot encoding for training purposes.\n",
    "- `imutable_cols` specifies a list of feature names that represent immutable features \n",
    "that we do not wish to change in the generated recourse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.data import TabularDataModuleConfigs, TabularDataModule, load_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc50927f",
   "metadata": {},
   "source": [
    "For example, to load the [adult](https://archive.ics.uci.edu/ml/datasets/adult) dataset,\n",
    "we can specify the `TabularDataModuleConfigs` as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706adffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = TabularDataModuleConfigs(\n",
    "    # The name of this dataset is \"adult\"\n",
    "    data_name=\"adult\",\n",
    "    # The data file is located in `../assets/data/s_adult.csv`.\n",
    "    data_dir=\"../assets/data/s_adult.csv\",\n",
    "    # Contains 2 features with continuous variables\n",
    "    continous_cols=[\"age\",\"hours_per_week\"],\n",
    "    # Contains 6 features with categorical (discrete) variables\n",
    "    discret_cols=[\"workclass\",\"education\",\"marital_status\",\"occupation\",\"race\",\"gender\"],\n",
    "    # Contains 2 features that we do not wish to change\n",
    "    imutable_cols=[\"race\", \"gender\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36385536",
   "metadata": {},
   "source": [
    "We can then pass `data_configs` to the `TabularDataModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57555f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = TabularDataModule(data_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6571d576",
   "metadata": {},
   "source": [
    "Alternatively, we can also specify this config via a *dictionary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebef567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This approach is equivalent to using `TabularDataModuleConfigs`\n",
    "data_config_dict = {\n",
    "    \"data_name\": \"adult\",\n",
    "    \"data_dir\": \"../assets/data/s_adult.csv\",\n",
    "    \"continous_cols\": [\"age\",\"hours_per_week\"],\n",
    "    \"discret_cols\": [\"workclass\",\"education\",\"marital_status\",\"occupation\",\"race\",\"gender\"],\n",
    "    \"imutable_cols\": [\"race\",\"gender\"]\n",
    "}\n",
    "datamodule = TabularDataModule(data_config_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af3b48bd",
   "metadata": {},
   "source": [
    "For datasets supported by `ReLax`, we can simply call `load_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fce1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to specifying configs for `TabularDataModule`\n",
    "datamodule = load_data('adult')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4803434",
   "metadata": {},
   "source": [
    "For more usage of loading datasets in `ReLax`, check out [the data module documentation](../01_data.module.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a88d0645",
   "metadata": {},
   "source": [
    "## Train the Classifier\n",
    "For the purpose of exposing full functionality of the framework, \n",
    "we will train the model using the built-in functions in `ReLax`,\n",
    "which uses [haiku](https://dm-haiku.readthedocs.io/en/latest/index.html)\n",
    "for building neural network blocks.\n",
    "However, the recourse algorithms in `ReLax` can generate explanations \n",
    "for **all** jax-based framework (e.g., flax, haiku, vanilla jax). \n",
    "\n",
    ":::{.callout-warning}\n",
    "The recourse algorithms in `ReLax` currently only supports binary classification. \n",
    "The output of the classifier must be a probability score (bounded by [0, 1]).\n",
    "Future support for multi-class classification is planned.\n",
    ":::\n",
    "\n",
    "Training a classifier using the built-in functions in `ReLax` is very simple. \n",
    "We will first specify the classifier. The classifier is called `PredictiveTrainingModule`, \n",
    "which specifies the model structure, and the optimization procedure \n",
    "(e.g., it specifies the loss function for optimizing the model).\n",
    "Next, we use `train_model` to train the model on `TabularDataModule`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b3cf023",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e914226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.module import PredictiveTrainingModuleConfigs, PredictiveTrainingModule"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc7c8b22",
   "metadata": {},
   "source": [
    "Defining `PredictiveTrainingModule` is similar to defining `TabularDataModule`.\n",
    "We first specify the configurator as `PredictiveTrainingModuleConfigs`,\n",
    "and pass this configurator to `PredictiveTrainingModule`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = PredictiveTrainingModuleConfigs(\n",
    "    lr=0.01, # Learning rate\n",
    "    sizes=[50, 10, 50], # The sizes of the hidden layers\n",
    "    dropout_rate=0.3 # Dropout rate\n",
    ")\n",
    "\n",
    "# specify the predictive model\n",
    "module = PredictiveTrainingModule(model_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae438a1b",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The training step for each batch is specified in `PredictiveTrainingModule`. \n",
    "Essentially, it will compute the binary cross-entropy loss for each batch, \n",
    "and apply backpropagation (via [adam](https://optax.readthedocs.io/en/latest/api.html#adam))\n",
    "to update parameters of the model.\n",
    ":::\n",
    "\n",
    "\n",
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29383a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.trainer import TrainingConfigs, train_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c36f447",
   "metadata": {},
   "source": [
    "To train `PredictiveTrainingModule` for the entire dataset (specified in `TabularDataModule`),\n",
    "we can simply call `train_model`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba44af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "2023-02-07 15:46:33.350353: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 15:46:33.351321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-07 15:46:33.351331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Epoch 9: 100%|██████████| 96/96 [00:01<00:00, 54.40batch/s, train/train_loss_1=0.0616]\n"
     ]
    }
   ],
   "source": [
    "trainer_config = TrainingConfigs(\n",
    "    n_epochs=10, # Number of epochs\n",
    "    batch_size=256, # Batch size\n",
    "    monitor_metrics='val/val_loss', # The metric to monitor\n",
    "    logger_name='pred' # The name of the logger\n",
    ")\n",
    "\n",
    "# train the model\n",
    "params, opt_state = train_model(\n",
    "    module, datamodule, trainer_config\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d5c9b61",
   "metadata": {},
   "source": [
    "### Make Predictions\n",
    "\n",
    "The forward pass is done via `PredictiveTrainingModule.forward`. \n",
    "We wrap the `pred_fn` as follows, which will be called later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_fn(x, params, rng_key):\n",
    "    return module.forward(params, rng_key, x, is_training=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d1f2129",
   "metadata": {},
   "source": [
    "## Generate Counterfactual Explanations\n",
    "\n",
    "Now, it is time to use `ReLax` to generate counterfactual explanations (or recourse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5587fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.methods import VanillaCF, VanillaCFConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a05346",
   "metadata": {},
   "source": [
    "We use `VanillaCF` (a very popular recourse generation algorithm) as an example for this tutorial.\n",
    "Defining `VanillaCF` is similar to defining `TabularDataModule` and `PredictiveTrainingModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_config = VanillaCFConfig(\n",
    "    n_steps=1000, # Number of steps\n",
    "    lr=0.001 # Learning rate\n",
    ")\n",
    "cf_exp = VanillaCF(cf_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "333e627f",
   "metadata": {},
   "source": [
    "Generate counterfactual examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1117363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.evaluate import generate_cf_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc711d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:10<00:00, 96.49it/s]\n"
     ]
    }
   ],
   "source": [
    "cf_results = generate_cf_explanations(\n",
    "    cf_exp, datamodule, pred_fn, \n",
    "    pred_fn_args={\n",
    "        'params': params, 'rng_key': jax.random.PRNGKey(0)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b704058",
   "metadata": {},
   "source": [
    "## Benchmark the Counterfactual Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47bd23",
   "metadata": {},
   "source": [
    "After we obtain the counterfactual results, we can use  `benchmark_cfs` to evaluate the accuracy, validity, and proximity of the counterfactual example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.evaluate import benchmark_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220009e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>validity</th>\n",
       "      <th>proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <th>VanillaCF</th>\n",
       "      <td>0.829751</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>7.896814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      acc  validity  proximity\n",
       "adult VanillaCF  0.829751  0.999754   7.896814"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_cfs([cf_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
